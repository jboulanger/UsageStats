{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Usage Stat analysis from a booking calendar\n",
    "\n",
    "Plot usage stats by user for the year\n",
    "\n",
    "conda install pandas, matplotlib, xlrd, ipykernel\n",
    "python -m ipykernel install --user --name usagestats\n",
    "\n",
    "\n",
    "Usage: \n",
    "- Set the list of files and the starting date and run the notebook\n",
    "- Check if there are no unknown group for the user, edit the users.csv file to update it if needed and run again the notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "start_date = '2020-11-02' # iso-format data yyyy-mm-dd\n",
    "num_weeks = 52\n",
    "file_list = glob.glob('*.xlsx')\n",
    "users_file = 'users.csv'\n",
    "groups_file = 'groups.csv'\n",
    "booking_types = ['service', 'maintenance', 'training']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime, date, timedelta\n",
    "import os.path\n",
    "\n",
    "def load_ics(filename,type_list):\n",
    "    \"\"\"Load data from an ics calendar file\"\"\"\n",
    "    from ics import Calendar\n",
    "    c = Calendar(open(filename).read())\n",
    "    ev = [e for e in c.events if e.organizer is not None]\n",
    "    d = {'User': [e.organizer.common_name for e in ev],\n",
    "         'Start': [e.begin.datetime for e in ev],\n",
    "         'End': [e.end.datetime for e in ev],\n",
    "         'Subject':[e.end.datetime for e in ev]\n",
    "    }\n",
    "    bookings['Duration'] = bookings['End'] - bookings['Start']\n",
    "    bookings['Hours'] = [x.total_seconds()/3600.0 for x in bookings['Duration']]\n",
    "    bookings['Type'] = [ get_booking_type(x,type_list) for x in bookings[\"Subject\"] ]\n",
    "    bookings['Subject'] = [x.lower().replace('maintenace','maintenance') for x in bookings['Subject']]\n",
    "    df = pd.DataFrame(d)\n",
    "    return df\n",
    "\n",
    "    \"\"\"Range of dates\"\"\"\n",
    "    curr = start\n",
    "    while curr < end:\n",
    "        yield curr\n",
    "        curr += step\n",
    "\n",
    "def get_booking_type(x,type_list):\n",
    "    \"\"\"Get the type of booking by matching test from type list\"\"\" \n",
    "    for t in type_list:\n",
    "        if x.lower().find(t)!=-1:\n",
    "            return t\n",
    "    return 'standard'    \n",
    "\n",
    "def to_date_time(str):\n",
    "    \"\"\"Convert a string to a datetime\"\"\"\n",
    "    try :\n",
    "        date = pd.to_datetime(str, format='%a %d/%m/%Y %H:%M')\n",
    "    except (TypeError,ValueError):\n",
    "        date = pd.to_datetime(str, format='%Y/%m/%d %H:%M:%S')\n",
    "    return date\n",
    "\n",
    "def load_file(filename,type_list):\n",
    "    \"\"\"Load a xlsx file with booking information\"\"\"\n",
    "    bookings = pd.read_excel(filename)\n",
    "    bookings.rename(columns={\"From\":\"User\"}, inplace=True)\n",
    "    bookings['Instrument'] = filename.replace('.xlsx','')\n",
    "    bookings['Start'] = [to_date_time(x) for x in bookings['Start']]\n",
    "    bookings['End'] = [to_date_time(x) for x in bookings['End']]    \n",
    "    bookings['Duration'] = bookings['End'] - bookings['Start']\n",
    "    bookings['Hours'] = [x.total_seconds()/3600.0 for x in bookings['Duration']]\n",
    "    bookings['Subject'] = [x.lower().replace('maintenace','maintenance') for x in bookings['Subject']]\n",
    "    bookings['Type'] = [ get_booking_type(x,type_list) for x in bookings['Subject'] ]    \n",
    "    return bookings\n",
    "\n",
    "def load_booking(file_list,type_list):\n",
    "    \"\"\"Load all bookings\"\"\"\n",
    "    df = []\n",
    "    for f in file_list:        \n",
    "        df.append(load_file(f,type_list))        \n",
    "    return pd.concat(df)\n",
    "\n",
    "def get_usage(week, bookings):\n",
    "    \"\"\"Get the amount of usage in hours per week\"\"\"\n",
    "    s = 0.0\n",
    "    for j, booking in bookings.iterrows():\n",
    "        d = (min(booking[\"End\"], week[\"End\"]) - max(booking[\"Start\"], week[\"Start\"])).total_seconds()\n",
    "        if d > 0.0:\n",
    "            s += d/3600.0\n",
    "    return s  \n",
    "\n",
    "def get_usage_by_instrument(bookings, start_date, num_weeks):\n",
    "    \"\"\"Get usage per instrument\"\"\"\n",
    "    start_date = datetime.fromisoformat(start_date)\n",
    "    end_date = start_date + timedelta(weeks = num_weeks)\n",
    "    weeks_start = [d for d in daterange(start_date,end_date,timedelta(days=7))]    \n",
    "    usage = []\n",
    "    for intrument in bookings[\"Instrument\"].unique():\n",
    "        df = pd.DataFrame()\n",
    "        df[\"Week\"] = pd.Series(range(1,len(weeks_start)+1))\n",
    "        df[\"Start\"] = weeks_start\n",
    "        df[\"End\"] = df[\"Start\"] + timedelta(days=7)\n",
    "        df[\"Instrument\"] = intrument\n",
    "        df[\"Usage\"] = [get_usage(w, bookings[bookings[\"Instrument\"]==intrument]) for i,w in df.iterrows()]       \n",
    "        usage.append(df)\n",
    "    return pd.concat(usage, ignore_index=True)\n",
    "\n",
    "def load_users(bookings, user_file):\n",
    "    \"\"\"List unique users from the bookings and list users\"\"\"\n",
    "    unique_users = pd.DataFrame({\"User\":bookings[\"User\"].unique()})\n",
    "    unique_users['Group'] = 'Unknown'\n",
    "    unique_users.set_index('User')\n",
    "    # merge with existing file\n",
    "    if os.path.isfile(users_file):\n",
    "        print('Loading Users and Groups from files', users_file)\n",
    "        tmp = pd.read_csv('users.csv')#.reset_index('User')    \n",
    "        #unique_users = pd.merge(tmp,unique_users) \n",
    "        users =  pd.merge(unique_users, tmp, how='right')\n",
    "    else:\n",
    "        users = unique_users\n",
    "    return users\n",
    "\n",
    "def load_groups(users, groups_file):\n",
    "    \"\"\"List unique groups from the bookings and list users\"\"\"\n",
    "    unique_groups = pd.DataFrame({\"Group\":users[\"Group\"].unique()})\n",
    "    unique_groups['Division'] = 'Unknown'\n",
    "    unique_groups.set_index('Group')\n",
    "    # merge with existing file\n",
    "    if os.path.isfile(groups_file):\n",
    "        print('Loading Groups from files', groups_file)\n",
    "        tmp = pd.read_csv(groups_file)    \n",
    "        groups =  pd.merge(unique_groups, tmp, how='right')\n",
    "    else:\n",
    "        groups = unique_groups        \n",
    "    return groups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting and loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the widget values\n",
    "bookings = load_booking(file_list, booking_types)\n",
    "bookings.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a list of all users and groups and save it to a file\n",
    "\n",
    "This also add the Group column to the bookings. At this point, we can edit the user.csv file and run this cell again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instrument_list = pd.DataFrame({\"Instrument\":bookings[\"Instrument\"].unique()})\n",
    "users = load_users(bookings, users_file)\n",
    "# save file to disk\n",
    "users.to_csv('users.csv',index=False)\n",
    "print(f'There were {len(users)} unique users on {len(instrument_list)} instruments')\n",
    "users.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from the list of users get the list of groups\n",
    "groups = load_groups(users, groups_file)\n",
    "# save file to disk\n",
    "groups.to_csv('groups.csv',index=False)\n",
    "print(f'There are {len(groups)} groups')\n",
    "groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bookings = load_booking(file_list, booking_types)\n",
    "bookings = pd.merge(bookings, users, left_on='User', right_on='User', how='left')\n",
    "bookings = pd.merge(bookings, groups, on='Group', how='left')\n",
    "bookings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bookings.to_csv('bookings.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Counts and usage by type of booking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bookings.groupby('Type').agg(Hours=pd.NamedAgg(column=\"Hours\", aggfunc=\"sum\"),\n",
    "                             Count=pd.NamedAgg(column=\"Hours\", aggfunc=\"count\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ti = bookings.groupby(['Type','Instrument'],as_index=False).agg(Hours=pd.NamedAgg(column=\"Hours\", aggfunc=\"sum\"),\n",
    "                                        Count=pd.NamedAgg(column=\"Hours\", aggfunc=\"count\")).pivot('Instrument','Type','Hours')\n",
    "ti.to_csv('booking-by-type-and-instrument.csv')\n",
    "\n",
    "ti.plot(kind='bar',stacked=True)\n",
    "plt.legend(bbox_to_anchor=(1,0.75))\n",
    "plt.title('Hours per type of bookings and instrument')\n",
    "plt.savefig('usage-per-type-per-instrument.pdf')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter out bookings to eliminate unwanted entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove special bookings\n",
    "bookings = bookings[ ~bookings['Type'].isin( ['service', 'maintenance'] ) ]\n",
    "# remove Analysis PC and other jokes\n",
    "bookings = bookings[~bookings.Instrument.isin(['Analysis PC 1','Analysis PC 2' ,'Analysis PC 3' ,'Analysis PC 4','SIM Analysis PC'])]\n",
    "bookings.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usage per groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "bookings.groupby(['Group','Instrument'], as_index=False)['Hours'].agg('sum').pivot(index=\"Group\",columns=\"Instrument\",values='Hours').fillna(0).to_csv('usage-per-group-per-instrument.csv')\n",
    "f,x = plt.subplots(figsize=(10,10))\n",
    "tmp = bookings.groupby(['Group','Instrument'], as_index=False)['Hours'].agg('sum')\n",
    "tmp['Hours'] = [math.log10(x) for x in tmp['Hours']]\n",
    "cmap = sns.color_palette(\"viridis\", as_cmap=True)\n",
    "sns.scatterplot(data=tmp, x='Instrument', y='Group', size='Hours', hue='Hours',palette=cmap)\n",
    "plt.xticks(rotation=90)\n",
    "plt.title('Usage per Group and per Instrument (excluding service, maintenance and PCs)\\n Logarithmic scale')\n",
    "plt.legend(title=\"Log Hours\")\n",
    "plt.savefig('usage-per-group-per-instrument.pdf')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_values_on_bars(axs, h_v=\"v\", space=0.4, hspace=0.5):\n",
    "    \"\"\"from https://stackoverflow.com/questions/43214978/seaborn-barplot-displaying-values\"\"\"\n",
    "    def _show_on_single_plot(ax):\n",
    "        if h_v == \"v\":\n",
    "            for p in ax.patches:\n",
    "                _x = p.get_x() + p.get_width() / 2\n",
    "                _y = p.get_y() + p.get_height()\n",
    "                value = int(p.get_height())\n",
    "                ax.text(_x, _y, value, ha=\"center\") \n",
    "        elif h_v == \"h\":\n",
    "            for p in ax.patches:\n",
    "                _x = p.get_x() + p.get_width() + float(space)\n",
    "                _y = p.get_y() + p.get_height() - p.get_height() * hspace\n",
    "                value = int(p.get_width())\n",
    "                ax.text(_x, _y, value, ha=\"left\")\n",
    "\n",
    "    if isinstance(axs, np.ndarray):\n",
    "        for idx, ax in np.ndenumerate(axs):\n",
    "            _show_on_single_plot(ax)\n",
    "    else:\n",
    "        _show_on_single_plot(axs)\n",
    "\n",
    "import numpy as np\n",
    "total_usage_hrs = bookings['Hours'].sum()\n",
    "df = bookings.groupby(['Group'],as_index=False).agg('sum')\n",
    "grp_order = np.flip(df['Hours'].to_numpy().argsort())\n",
    "f, ax = plt.subplots(figsize=(6, 10))\n",
    "sns.barplot(data=df,y='Group',x='Hours',order=df['Group'][grp_order])\n",
    "show_values_on_bars(ax,'h',hspace=0.25)\n",
    "plt.title(f'Total usage per group (excluding service, maintenance and PCs) \\n Grand total: {total_usage_hrs:.0f} Hours ')\n",
    "plt.xlim([0, 1.2*df['Hours'].max()])\n",
    "plt.savefig('usage-per-group.pdf',pad_inches=1.2,bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistics per division"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sum usage hours per division\n",
    "per_division = bookings.groupby(['Division'],as_index=False)['Hours'].agg('sum')\n",
    "grp_order = np.flip(per_division ['Hours'].to_numpy().argsort())\n",
    "f, ax = plt.subplots(figsize=(6, 10))\n",
    "sns.barplot(data=per_division ,y='Division',x='Hours',order=per_division['Division'][grp_order])\n",
    "show_values_on_bars(ax,'h')\n",
    "total_usage_hrs = bookings['Hours'].sum()\n",
    "plt.title(f'Total hours per division (excluding service, maintenance and PCs) \\n Grand total: {total_usage_hrs:.0f} Hours ')\n",
    "plt.xlim([0, 1.2*per_division['Hours'].max()])\n",
    "plt.xlabel('Total usage [Hours]')\n",
    "plt.savefig('usage-per-division.pdf',pad_inches=1.2,bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Usage for each week and each instrument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "usage = get_usage_by_instrument(bookings, start_date=start_date, num_weeks=num_weeks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(data=usage[usage['Usage']>0].sort_values('Instrument'),x='Week',y='Instrument',hue='Usage',size='Usage')\n",
    "plt.legend(bbox_to_anchor=(1,0.7))\n",
    "plt.title('Usage per week and per instrument (excluding service, maintenance and PCs)')\n",
    "plt.savefig('usage-per-instrument-per-week-blot.pdf',pad_inches=1.2,bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# figure for each instruments\n",
    "col_order = [*usage['Instrument'].unique()]\n",
    "col_order.sort()\n",
    "g = sns.FacetGrid(usage, col=\"Instrument\",col_wrap=4,col_order=col_order)\n",
    "p = g.map(sns.barplot,\"Week\",\"Usage\",order=np.arange(num_weeks))\n",
    "averages = usage.groupby('Instrument')['Usage'].agg(['mean'])\n",
    "avg_global = averages.mean()[0]\n",
    "for k, a in enumerate(p.axes):        \n",
    "    mic = a.get_title().replace('Instrument = ','')    \n",
    "    avg = averages['mean'][mic]\n",
    "    a.set_title(f'{mic} - average:{avg:.0f}h/w')\n",
    "    a.axhline(avg_global, color='r', linestyle='-')    \n",
    "    a.axhline(avg, color='g', linestyle='-')\n",
    "    a.set_ylabel('Usage [Hours/Week]')\n",
    "    a.set_xticks(np.arange(0,num_weeks,step=10))\n",
    "    a.set_xticklabels(np.arange(0,num_weeks,step=10))\n",
    "p.fig.subplots_adjust(top=0.9)\n",
    "p.fig.suptitle('Usage per week and per instrument (excluding service, maintenance and PCs)')\n",
    "plt.savefig('usage-per-instrument-per-week.pdf')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save usage to a csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the data in a file\n",
    "usage.pivot(index=\"Week\",columns=\"Instrument\",values=\"Usage\").to_csv('usage-per-instrument-per-week.csv')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "de79715f9c4194c3c7c6104090a45920f7e546a5b3b8a6d118865ed18b07dca5"
  },
  "kernelspec": {
   "display_name": "usagestats",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
